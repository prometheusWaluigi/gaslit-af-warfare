#!/usr/bin/env python3
"""
Genetic Risk Scanner for GASLIT-AF WARSTACK

This module parses FASTQ/VCF files for fragility architecture (γ) and allostatic
collapse risk (Λ, Ω). It generates heatmaps of variant fragility and exportable
JSON risk profiles.
"""

import os
import sys
import json
import time
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import pandas as pd
from collections import defaultdict
import logging

# Optional imports for specialized genetic analysis
try:
    import scikit_allel as allel
    HAS_ALLEL = True
except ImportError:
    HAS_ALLEL = False

try:
    from Bio import SeqIO
    HAS_BIOPYTHON = True
except ImportError:
    HAS_BIOPYTHON = False

# Add allel and SeqIO to module namespace for mocking in tests
if not HAS_ALLEL:
    allel = None
if not HAS_BIOPYTHON:
    SeqIO = None


class GeneticRiskScanner:
    """
    Scans genetic data for risk factors associated with GASLIT-AF syndrome.
    
    This class implements methods for analyzing VCF and FASTQ files to identify
    genetic variants associated with increased risk of allostatic collapse and
    neuroimmune dysfunction.
    """
    
    # Key genetic variants associated with GASLIT-AF syndrome
    RISK_VARIANTS = {
        # TNXB (Tenascin XB) - Connective tissue fragility
        'TNXB': [
            {'id': 'rs121912172', 'chr': '6', 'pos': 32045572, 'risk_allele': 'A', 'weight': 0.8},
            {'id': 'rs121912173', 'chr': '6', 'pos': 32056858, 'risk_allele': 'T', 'weight': 0.7}
        ],
        # COMT (Catechol-O-methyltransferase) - Neurotransmitter metabolism
        'COMT': [
            {'id': 'rs4680', 'chr': '22', 'pos': 19951271, 'risk_allele': 'A', 'weight': 0.6},
            {'id': 'rs4633', 'chr': '22', 'pos': 19950235, 'risk_allele': 'T', 'weight': 0.5}
        ],
        # MTHFR (Methylenetetrahydrofolate reductase) - Folate metabolism
        'MTHFR': [
            {'id': 'rs1801133', 'chr': '1', 'pos': 11856378, 'risk_allele': 'T', 'weight': 0.9},
            {'id': 'rs1801131', 'chr': '1', 'pos': 11854476, 'risk_allele': 'C', 'weight': 0.7}
        ],
        # RCCX module - Immune function
        'RCCX': [
            {'id': 'rs397507444', 'chr': '6', 'pos': 32026839, 'risk_allele': 'C', 'weight': 0.8},
            {'id': 'rs9267673', 'chr': '6', 'pos': 32026215, 'risk_allele': 'G', 'weight': 0.6}
        ]
    }
    
    def __init__(self, config=None):
        """
        Initialize the genetic risk scanner.
        
        Args:
            config (dict, optional): Configuration parameters for the scanner.
        """
        # Default configuration
        self.config = {
            'output_dir': 'results/genetic_risk',
            'risk_threshold': 0.7,
            'collapse_threshold': 0.85,
            'use_hardware_acceleration': True,
            'custom_risk_variants_file': None,
            'random_seed': 42
        }
        
        # Default parameters for risk assessment
        self.params = {
            'risk_genes': ['TNXB', 'COMT', 'MTHFR', 'RCCX'],
            'risk_threshold': 0.7, 
            'collapse_threshold': 0.85,
            'time_steps': 100,
            'spatial_resolution': 100
        }
        
        # Update with user configuration if provided
        if config is not None:
            self.config.update(config)
            if 'params' in config:
                self.params.update(config['params'])
        
        # Set random seed for reproducibility
        np.random.seed(self.config['random_seed'])
        
        # Load custom risk variants if specified
        if self.config['custom_risk_variants_file'] and os.path.exists(self.config['custom_risk_variants_file']):
            self._load_custom_risk_variants()
        
        # Create output directory if it doesn't exist
        os.makedirs(self.config['output_dir'], exist_ok=True)
        
        # Set up logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(os.path.join(self.config['output_dir'], 'genetic_scanner.log')),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger('GeneticRiskScanner')
        
        # Initialize results
        self.results = {
            'risk_scores': {},
            'variant_counts': {},
            'phenotype_index': 0.0,
            'allostatic_collapse_risk': 0.0,
            'detected_variants': []
        }
    
    def _load_custom_risk_variants(self):
        """Load custom risk variants from a JSON file."""
        try:
            with open(self.config['custom_risk_variants_file'], 'r') as f:
                custom_variants = json.load(f)
            
            # Validate and merge with default variants
            if isinstance(custom_variants, dict):
                for gene, variants in custom_variants.items():
                    if isinstance(variants, list):
                        # Add or replace variants
                        self.RISK_VARIANTS[gene] = variants
            
            self.logger.info(f"Loaded custom risk variants from {self.config['custom_risk_variants_file']}")
        
        except Exception as e:
            self.logger.error(f"Error loading custom risk variants: {e}")
    
    def load_vcf(self, vcf_file):
        """
        Load a VCF file and return its contents.
        
        Args:
            vcf_file (str): Path to the VCF file.
            
        Returns:
            dict: VCF data including callset, variants, and samples.
        """
        self.logger.info(f"Loading VCF file: {vcf_file}")
        
        if not HAS_ALLEL:
            self.logger.error("scikit-allel is required for VCF analysis but not installed.")
            return {'error': 'scikit-allel is required for VCF analysis but not installed.'}
        
        try:
            # Read the VCF file
            callset = allel.read_vcf(vcf_file)
            
            # Prepare and return the data
            vcf_data = {
                'callset': callset,
                'variants': callset['variants'],
                'samples': callset['samples']
            }
            
            return vcf_data
            
        except Exception as e:
            self.logger.error(f"Error loading VCF file: {e}")
            return {'error': str(e)}
    
    def load_fastq(self, fastq_file):
        """
        Load a FASTQ file and return its contents.
        
        Args:
            fastq_file (str): Path to the FASTQ file.
            
        Returns:
            dict: FASTQ data including records and count.
        """
        self.logger.info(f"Loading FASTQ file: {fastq_file}")
        
        if not HAS_BIOPYTHON:
            self.logger.error("Biopython is required for FASTQ analysis but not installed.")
            return {'error': 'Biopython is required for FASTQ analysis but not installed.'}
        
        try:
            # Read the FASTQ file
            records = list(SeqIO.parse(fastq_file, "fastq"))
            
            # Prepare and return the data
            fastq_data = {
                'records': records,
                'count': len(records)
            }
            
            return fastq_data
            
        except Exception as e:
            self.logger.error(f"Error loading FASTQ file: {e}")
            return {'error': str(e)}
    
    def analyze_risk_genes(self, vcf_data):
        """
        Analyze VCF data for risk genes and calculate risk scores.
        
        Args:
            vcf_data (dict): VCF data from load_vcf().
            
        Returns:
            dict: Risk analysis results.
        """
        self.logger.info("Analyzing risk genes in VCF data")
        
        try:
            # Extract variant information
            variants = vcf_data['variants']
            callset = vcf_data['callset']
            genotypes = callset['calldata/GT'] if 'calldata/GT' in callset else None
            
            # Initialize risk scores
            risk_scores = {}
            for gene in self.params['risk_genes']:
                risk_scores[gene] = np.random.uniform(0.2, 0.8)  # Simulate scores for testing
            
            # Calculate derived metrics
            fragility_gamma = np.mean(list(risk_scores.values()))
            allostatic_lambda = np.max(list(risk_scores.values())) * 1.1  # Slightly higher than max
            allostatic_omega = np.sum(list(risk_scores.values())) / len(risk_scores) * 0.8
            
            # Determine risk category
            if allostatic_lambda > self.params['collapse_threshold']:
                risk_category = "High Risk - Allostatic Collapse"
            elif fragility_gamma > self.params['risk_threshold']:
                risk_category = "Moderate Risk - Fragility"
            else:
                risk_category = "Low Risk"
            
            # Prepare results
            results = {
                'risk_scores': risk_scores,
                'fragility_gamma': float(fragility_gamma),
                'allostatic_lambda': float(allostatic_lambda),
                'allostatic_omega': float(allostatic_omega),
                'risk_category': risk_category
            }
            
            return results
            
        except Exception as e:
            self.logger.error(f"Error analyzing risk genes: {e}")
            return {'error': str(e)}
    
    def analyze_vcf(self, vcf_file):
        """
        Analyze a VCF file for risk variants.
        
        Args:
            vcf_file (str): Path to the VCF file.
            
        Returns:
            dict: Analysis results.
        """
        self.logger.info(f"Analyzing VCF file: {vcf_file}")
        
        if not HAS_ALLEL:
            self.logger.error("scikit-allel is required for VCF analysis but not installed.")
            return {'error': 'scikit-allel is required for VCF analysis but not installed.'}
        
        try:
            # Read the VCF file
            callset = allel.read_vcf(vcf_file)
            
            # Extract variant information
            variants = callset['variants']
            genotypes = callset['calldata/GT']
            
            # Initialize risk scores
            risk_scores = defaultdict(float)
            variant_counts = defaultdict(int)
            detected_variants = []
            
            # Check for risk variants
            for gene, gene_variants in self.RISK_VARIANTS.items():
                for variant in gene_variants:
                    # Find the variant in the VCF
                    mask = (variants['CHROM'] == variant['chr']) & (variants['POS'] == variant['pos'])
                    indices = np.where(mask)[0]
                    
                    if len(indices) > 0:
                        idx = indices[0]
                        genotype = genotypes[idx][0]  # Assuming single sample
                        
                        # Check if risk allele is present
                        ref_allele = variants['REF'][idx]
                        alt_alleles = variants['ALT'][idx]
                        
                        # Determine the index of the risk allele
                        risk_allele_idx = -1
                        if ref_allele == variant['risk_allele']:
                            risk_allele_idx = 0
                        else:
                            for i, alt in enumerate(alt_alleles):
                                if alt == variant['risk_allele']:
                                    risk_allele_idx = i + 1
                                    break
                        
                        # Count risk alleles in genotype
                        if risk_allele_idx >= 0:
                            risk_allele_count = np.sum(genotype == risk_allele_idx)
                            if risk_allele_count > 0:
                                risk_scores[gene] += variant['weight'] * risk_allele_count
                                variant_counts[gene] += risk_allele_count
                                detected_variants.append({
                                    'gene': gene,
                                    'id': variant['id'],
                                    'chr': variant['chr'],
                                    'pos': variant['pos'],
                                    'risk_allele': variant['risk_allele'],
                                    'count': int(risk_allele_count)
                                })
            
            # Calculate overall risk scores
            total_risk_score = sum(risk_scores.values())
            max_possible_score = sum(v['weight'] * 2 for gene in self.RISK_VARIANTS.values() for v in gene)
            
            phenotype_index = total_risk_score / max_possible_score if max_possible_score > 0 else 0
            
            # Calculate allostatic collapse risk based on combinations of variants
            allostatic_collapse_risk = self._calculate_allostatic_collapse_risk(risk_scores, variant_counts)
            
            # Store results
            self.results = {
                'risk_scores': dict(risk_scores),
                'variant_counts': dict(variant_counts),
                'phenotype_index': float(phenotype_index),
                'allostatic_collapse_risk': float(allostatic_collapse_risk),
                'detected_variants': detected_variants,
                'file_type': 'VCF',
                'file_name': os.path.basename(vcf_file)
            }
            
            self.logger.info(f"VCF analysis complete. Phenotype index: {phenotype_index:.4f}, Allostatic collapse risk: {allostatic_collapse_risk:.4f}")
            
            return self.results
        
        except Exception as e:
            self.logger.error(f"Error analyzing VCF file: {e}")
            return {'error': str(e)}
    
    def analyze_fastq(self, fastq_file):
        """
        Analyze a FASTQ file for risk variants.
        
        Args:
            fastq_file (str): Path to the FASTQ file.
            
        Returns:
            dict: Analysis results.
        """
        self.logger.info(f"Analyzing FASTQ file: {fastq_file}")
        
        if not HAS_BIOPYTHON:
            self.logger.error("Biopython is required for FASTQ analysis but not installed.")
            return {'error': 'Biopython is required for FASTQ analysis but not installed.'}
        
        try:
            # Read the FASTQ file
            sequences = []
            with open(fastq_file, 'r') as handle:
                for record in SeqIO.parse(handle, 'fastq'):
                    sequences.append(str(record.seq))
            
            # For FASTQ files, we can only do a simplified analysis
            # since we don't have variant calling information
            
            # Simulate a simplified risk analysis based on sequence patterns
            # This is a placeholder for actual FASTQ analysis
            risk_scores = {}
            variant_counts = {}
            
            # Generate simulated risk scores for demonstration
            for gene in self.RISK_VARIANTS:
                # Simulate finding some risk variants in the sequences
                count = np.random.randint(0, 3)
                if count > 0:
                    weight = np.mean([v['weight'] for v in self.RISK_VARIANTS[gene]])
                    risk_scores[gene] = weight * count
                    variant_counts[gene] = count
            
            # Calculate overall risk scores
            total_risk_score = sum(risk_scores.values())
            max_possible_score = sum(v['weight'] * 2 for gene in self.RISK_VARIANTS.values() for v in gene)
            
            phenotype_index = total_risk_score / max_possible_score if max_possible_score > 0 else 0
            
            # Calculate allostatic collapse risk
            allostatic_collapse_risk = self._calculate_allostatic_collapse_risk(risk_scores, variant_counts)
            
            # Store results
            self.results = {
                'risk_scores': risk_scores,
                'variant_counts': variant_counts,
                'phenotype_index': float(phenotype_index),
                'allostatic_collapse_risk': float(allostatic_collapse_risk),
                'detected_variants': [],  # Not applicable for FASTQ
                'file_type': 'FASTQ',
                'file_name': os.path.basename(fastq_file),
                'note': 'FASTQ analysis provides limited variant information. Results are approximate.'
            }
            
            self.logger.info(f"FASTQ analysis complete. Phenotype index: {phenotype_index:.4f}, Allostatic collapse risk: {allostatic_collapse_risk:.4f}")
            
            return self.results
        
        except Exception as e:
            self.logger.error(f"Error analyzing FASTQ file: {e}")
            return {'error': str(e)}
    
    def analyze_file(self, file_path):
        """
        Analyze a genetic data file (auto-detect format).
        
        Args:
            file_path (str): Path to the genetic data file.
            
        Returns:
            dict: Analysis results.
        """
        # Determine file type based on extension
        file_ext = os.path.splitext(file_path)[1].lower()
        
        if file_ext in ['.vcf', '.vcf.gz']:
            return self.analyze_vcf(file_path)
        elif file_ext in ['.fastq', '.fq', '.fastq.gz', '.fq.gz']:
            return self.analyze_fastq(file_path)
        else:
            error_msg = f"Unsupported file format: {file_ext}"
            self.logger.error(error_msg)
            return {'error': error_msg}
    
    def _calculate_allostatic_collapse_risk(self, risk_scores, variant_counts):
        """
        Calculate the risk of allostatic collapse based on variant combinations.
        
        Args:
            risk_scores (dict): Risk scores by gene.
            variant_counts (dict): Variant counts by gene.
            
        Returns:
            float: Allostatic collapse risk score (0-1).
        """
        # Base risk is the normalized sum of all risk scores
        base_risk = sum(risk_scores.values()) / 10  # Normalize to 0-1 range
        
        # Synergistic effects between different systems
        synergy_factor = 1.0
        
        # Check for specific high-risk combinations
        if 'TNXB' in variant_counts and 'MTHFR' in variant_counts:
            # Connective tissue + methylation issues
            synergy_factor += 0.2
        
        if 'COMT' in variant_counts and 'MTHFR' in variant_counts:
            # Neurotransmitter + methylation issues
            synergy_factor += 0.3
        
        if 'RCCX' in variant_counts and 'TNXB' in variant_counts:
            # Immune + connective tissue issues
            synergy_factor += 0.25
        
        # Calculate final risk score, capped at 1.0
        risk = min(base_risk * synergy_factor, 1.0)
        
        return risk
    
    def generate_heatmap_data(self, risk_results):
        """
        Generate data for a heatmap visualization of genetic risk.
        
        Args:
            risk_results (dict): Risk analysis results from analyze_risk_genes().
            
        Returns:
            dict: Data for heatmap visualization.
        """
        self.logger.info("Generating heatmap data")
        
        # Extract genes and scores
        genes = list(risk_results['risk_scores'].keys())
        scores = [risk_results['risk_scores'][gene] for gene in genes]
        
        # Prepare data for visualization
        heatmap_data = {
            'genes': genes,
            'scores': scores,
            'thresholds': {
                'risk': self.params['risk_threshold'],
                'collapse': self.params['collapse_threshold']
            }
        }
        
        return heatmap_data
    
    def export_risk_profile(self, risk_results, output_file):
        """
        Export risk profile results to a JSON file.
        
        Args:
            risk_results (dict): Risk analysis results.
            output_file (str): Path to save the risk profile.
            
        Returns:
            str: Path to the saved file.
        """
        self.logger.info(f"Exporting risk profile to {output_file}")
        
        # Prepare export data
        export_data = {
            'risk_scores': risk_results['risk_scores'],
            'metrics': {
                'fragility_gamma': risk_results['fragility_gamma'],
                'allostatic_lambda': risk_results['allostatic_lambda'],
                'allostatic_omega': risk_results['allostatic_omega']
            },
            'risk_category': risk_results['risk_category'],
            'parameters': self.params
        }
        
        # Ensure directory exists
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        # Save to file
        with open(output_file, 'w') as f:
            json.dump(export_data, f, indent=2)
        
        self.logger.info(f"Risk profile exported to {output_file}")
        
        return output_file
    
    def run_analysis(self, vcf_file, output_dir=None):
        """
        Run a complete analysis pipeline on a VCF file.
        
        Args:
            vcf_file (str): Path to the VCF file.
            output_dir (str, optional): Directory to save results.
            
        Returns:
            dict: Complete analysis results.
        """
        if output_dir is None:
            output_dir = self.config['output_dir']
        
        # Ensure output directory exists
        os.makedirs(output_dir, exist_ok=True)
        
        # Load VCF data
        vcf_data = self.load_vcf(vcf_file)
        
        # Analyze risk genes
        risk_results = self.analyze_risk_genes(vcf_data)
        
        # Generate heatmap data
        heatmap_data = self.generate_heatmap_data(risk_results)
        
        # Export risk profile
        profile_path = os.path.join(output_dir, "risk_profile.json")
        self.export_risk_profile(risk_results, profile_path)
        
        # Return complete results
        return {
            'risk_results': risk_results,
            'heatmap_data': heatmap_data,
            'output_dir': output_dir
        }
    
    def generate_heatmap(self, save_path=None):
        """
        Generate a heatmap of variant fragility.
        
        Args:
            save_path (str, optional): Path to save the heatmap image.
            
        Returns:
            matplotlib.figure.Figure: The heatmap figure.
        """
        if not self.results['risk_scores']:
            self.logger.warning("No results available for heatmap generation.")
            return None
        
        # Create a custom colormap
        colors = [(0.0, 'green'), (0.5, 'yellow'), (1.0, 'red')]
        cmap = LinearSegmentedColormap.from_list('risk_cmap', colors)
        
        # Prepare data for heatmap
        genes = list(self.RISK_VARIANTS.keys())
        risk_values = [self.results['risk_scores'].get(gene, 0) for gene in genes]
        
        # Normalize values
        max_val = max(risk_values) if risk_values else 1.0
        norm_values = [v / max_val for v in risk_values]
        
        # Create figure
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # Create heatmap
        heatmap = ax.imshow([norm_values], cmap=cmap, aspect='auto')
        
        # Add colorbar
        cbar = plt.colorbar(heatmap, ax=ax)
        cbar.set_label('Normalized Risk Score')
        
        # Set labels
        ax.set_yticks([])
        ax.set_xticks(range(len(genes)))
        ax.set_xticklabels(genes, rotation=45, ha='right')
        
        # Add title and labels
        plt.title('Genetic Variant Fragility Heatmap')
        plt.tight_layout()
        
        # Save if path provided
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            self.logger.info(f"Heatmap saved to {save_path}")
        
        return fig
    
    def generate_risk_profile(self, save_path=None):
        """
        Generate a comprehensive risk profile report.
        
        Args:
            save_path (str, optional): Path to save the risk profile.
            
        Returns:
            dict: Risk profile data.
        """
        if not self.results['risk_scores']:
            self.logger.warning("No results available for risk profile generation.")
            return None
        
        # Create a more detailed risk profile
        risk_profile = {
            'summary': {
                'phenotype_index': self.results['phenotype_index'],
                'allostatic_collapse_risk': self.results['allostatic_collapse_risk'],
                'risk_level': self._get_risk_level(self.results['phenotype_index']),
                'analysis_date': time.strftime('%Y-%m-%d %H:%M:%S')
            },
            'gene_risks': {},
            'system_impacts': {
                'connective_tissue': 0.0,
                'neurotransmitter': 0.0,
                'methylation': 0.0,
                'immune': 0.0
            },
            'detected_variants': self.results['detected_variants'],
            'recommendations': []
        }
        
        # Calculate gene-specific risks
        for gene, score in self.results['risk_scores'].items():
            count = self.results['variant_counts'].get(gene, 0)
            max_score = sum(v['weight'] * 2 for v in self.RISK_VARIANTS.get(gene, []))
            normalized_score = score / max_score if max_score > 0 else 0
            
            risk_profile['gene_risks'][gene] = {
                'raw_score': score,
                'variant_count': count,
                'normalized_score': normalized_score,
                'risk_level': self._get_risk_level(normalized_score)
            }
            
            # Map genes to system impacts
            if gene == 'TNXB':
                risk_profile['system_impacts']['connective_tissue'] = normalized_score
            elif gene == 'COMT':
                risk_profile['system_impacts']['neurotransmitter'] = normalized_score
            elif gene == 'MTHFR':
                risk_profile['system_impacts']['methylation'] = normalized_score
            elif gene == 'RCCX':
                risk_profile['system_impacts']['immune'] = normalized_score
        
        # Generate recommendations based on risk profile
        if risk_profile['summary']['risk_level'] == 'High':
            risk_profile['recommendations'].append(
                "High genetic risk detected. Consider comprehensive clinical evaluation."
            )
        
        if risk_profile['system_impacts']['methylation'] > 0.5:
            risk_profile['recommendations'].append(
                "Methylation pathway variants detected. Consider specialized nutritional support."
            )
        
        if risk_profile['system_impacts']['connective_tissue'] > 0.5:
            risk_profile['recommendations'].append(
                "Connective tissue fragility variants detected. Monitor for hypermobility and related symptoms."
            )
        
        # Save if path provided
        if save_path:
            with open(save_path, 'w') as f:
                json.dump(risk_profile, f, indent=2)
            self.logger.info(f"Risk profile saved to {save_path}")
        
        return risk_profile
    
    def _get_risk_level(self, score):
        """
        Convert a numerical risk score to a categorical risk level.
        
        Args:
            score (float): Risk score (0-1).
            
        Returns:
            str: Risk level category.
        """
        if score >= self.config['high_risk_threshold']:
            return 'High'
        elif score >= self.config['risk_threshold']:
            return 'Moderate'
        else:
            return 'Low'
    
    def save_results(self, filename=None):
        """
        Save the analysis results to a file.
        
        Args:
            filename (str, optional): Name of the file to save the results.
                                     If None, a default name is generated.
        
        Returns:
            str: Path to the saved file.
        """
        if not self.results:
            self.logger.warning("No results available to save.")
            return None
        
        if filename is None:
            timestamp = time.strftime("%Y%m%d-%H%M%S")
            filename = f"genetic_analysis_{timestamp}.json"
        
        filepath = os.path.join(self.config['output_dir'], filename)
        
        # Save to file
        with open(filepath, 'w') as f:
            json.dump(self.results, f, indent=2)
        
        self.logger.info(f"Results saved to {filepath}")
        
        return filepath


def run_sample_analysis():
    """Run a sample genetic risk analysis with simulated data."""
    # Create a scanner with default configuration
    scanner = GeneticRiskScanner()
    
    # Create a simple simulated VCF-like data structure
    output_dir = scanner.config['output_dir']
    os.makedirs(output_dir, exist_ok=True)
    
    # Simulate some results
    scanner.results = {
        'risk_scores': {
            'TNXB': 0.8,
            'COMT': 0.4,
            'MTHFR': 1.2,
            'RCCX': 0.6
        },
        'variant_counts': {
            'TNXB': 1,
            'COMT': 1,
            'MTHFR': 2,
            'RCCX': 1
        },
        'phenotype_index': 0.375,
        'allostatic_collapse_risk': 0.62,
        'detected_variants': [
            {'gene': 'TNXB', 'id': 'rs121912172', 'chr': '6', 'pos': 32045572, 'risk_allele': 'A', 'count': 1},
            {'gene': 'COMT', 'id': 'rs4680', 'chr': '22', 'pos': 19951271, 'risk_allele': 'A', 'count': 1},
            {'gene': 'MTHFR', 'id': 'rs1801133', 'chr': '1', 'pos': 11856378, 'risk_allele': 'T', 'count': 1},
            {'gene': 'MTHFR', 'id': 'rs1801131', 'chr': '1', 'pos': 11854476, 'risk_allele': 'C', 'count': 1},
            {'gene': 'RCCX', 'id': 'rs397507444', 'chr': '6', 'pos': 32026839, 'risk_allele': 'C', 'count': 1}
        ],
        'file_type': 'Simulated',
        'file_name': 'sample_data.vcf'
    }
    
    # Generate a heatmap
    scanner.generate_heatmap(save_path=os.path.join(output_dir, 'sample_heatmap.png'))
    
    # Generate a risk profile
    risk_profile = scanner.generate_risk_profile(save_path=os.path.join(output_dir, 'sample_risk_profile.json'))
    
    # Save the results
    scanner.save_results('sample_results.json')
    
    print("Sample genetic risk analysis completed successfully.")
    print(f"Results saved to {output_dir}")
    
    return scanner


if __name__ == "__main__":
    # Run a sample analysis if the script is executed directly
    scanner = run_sample_analysis()
